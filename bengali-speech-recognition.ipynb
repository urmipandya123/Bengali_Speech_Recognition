{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r ../input/python-packages2 ./","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-28T11:48:22.971832Z","iopub.execute_input":"2023-07-28T11:48:22.972199Z","iopub.status.idle":"2023-07-28T11:48:24.343888Z","shell.execute_reply.started":"2023-07-28T11:48:22.972170Z","shell.execute_reply":"2023-07-28T11:48:24.342200Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!tar xvfz ./python-packages2/jiwer.tgz\n!pip install ./jiwer/jiwer-2.3.0-py3-none-any.whl -f ./ --no-index\n!tar xvfz ./python-packages2/normalizer.tgz\n!pip install ./normalizer/bnunicodenormalizer-0.0.24.tar.gz -f ./ --no-index\n!tar xvfz ./python-packages2/pyctcdecode.tgz\n!pip install ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/pygtrie-2.5.0.tar.gz -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n!pip install ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n\n!tar xvfz ./python-packages2/pypikenlm.tgz\n!pip install ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz -f ./ --no-index --no-deps","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:48:30.294257Z","iopub.execute_input":"2023-07-28T11:48:30.294980Z","iopub.status.idle":"2023-07-28T11:49:54.385479Z","shell.execute_reply.started":"2023-07-28T11:48:30.294939Z","shell.execute_reply":"2023-07-28T11:49:54.384108Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"jiwer/\njiwer/jiwer-2.3.0-py3-none-any.whl\njiwer/python-Levenshtein-0.12.2.tar.gz\njiwer/setuptools-65.3.0-py3-none-any.whl\nLooking in links: ./\nProcessing ./jiwer/jiwer-2.3.0-py3-none-any.whl\nINFO: pip is looking at multiple versions of jiwer to determine which version is compatible with other requirements. This could take a while.\n\u001b[31mERROR: Could not find a version that satisfies the requirement python-Levenshtein==0.12.2 (from jiwer) (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for python-Levenshtein==0.12.2\u001b[0m\u001b[31m\n\u001b[0mnormalizer/\nnormalizer/bnunicodenormalizer-0.0.24.tar.gz\nLooking in links: ./\nProcessing ./normalizer/bnunicodenormalizer-0.0.24.tar.gz\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: bnunicodenormalizer\n  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.0.24-py3-none-any.whl size=17628 sha256=dac29f2394794489ba255c22ea989cd8a574848d278cffd518b8bf3091a8ce4e\n  Stored in directory: /root/.cache/pip/wheels/78/d7/75/6986dc3616718f950b80e3bd79a796ef618eaef6cd800e7909\nSuccessfully built bnunicodenormalizer\nInstalling collected packages: bnunicodenormalizer\nSuccessfully installed bnunicodenormalizer-0.0.24\npyctcdecode/\npyctcdecode/hypothesis-6.54.4-py3-none-any.whl\npyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl\npyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl\npyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl\npyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\npyctcdecode/attrs-22.1.0-py2.py3-none-any.whl\npyctcdecode/pygtrie-2.5.0.tar.gz\nLooking in links: ./\nProcessing ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl\nInstalling collected packages: attrs\n  Attempting uninstall: attrs\n    Found existing installation: attrs 23.1.0\n    Uninstalling attrs-23.1.0:\n      Successfully uninstalled attrs-23.1.0\nSuccessfully installed attrs-22.1.0\nLooking in links: ./\nProcessing ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl\nInstalling collected packages: exceptiongroup\n  Attempting uninstall: exceptiongroup\n    Found existing installation: exceptiongroup 1.1.1\n    Uninstalling exceptiongroup-1.1.1:\n      Successfully uninstalled exceptiongroup-1.1.1\nSuccessfully installed exceptiongroup-1.0.0rc9\nLooking in links: ./\nProcessing ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl\nInstalling collected packages: hypothesis\nSuccessfully installed hypothesis-6.54.4\nLooking in links: ./\n\u001b[31mERROR: numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n\u001b[0mLooking in links: ./\nProcessing ./pyctcdecode/pygtrie-2.5.0.tar.gz\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: pygtrie\n  Building wheel for pygtrie (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pygtrie: filename=pygtrie-2.5.0-py3-none-any.whl size=20945 sha256=72d30b475ca99657c0acadd21bd86e5824ca1a2b9f0edb41cab9d9e0f0f25414\n  Stored in directory: /root/.cache/pip/wheels/78/28/09/b62c97a3e77102645c7ecc78c97580ad57090b1eee5438d6ac\nSuccessfully built pygtrie\nInstalling collected packages: pygtrie\nSuccessfully installed pygtrie-2.5.0\nLooking in links: ./\nProcessing ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl\nsortedcontainers is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nLooking in links: ./\nProcessing ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl\nInstalling collected packages: pyctcdecode\nSuccessfully installed pyctcdecode-0.4.0\npypikenlm/\npypikenlm/pypi-kenlm-0.1.20220713.tar.gz\nLooking in links: ./\nProcessing ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: pypi-kenlm\n  Building wheel for pypi-kenlm (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypi-kenlm: filename=pypi_kenlm-0.1.20220713-cp310-cp310-linux_x86_64.whl size=333264 sha256=fe068eceb1847d62fe3b9bd763810ad2688b2315dc36b76d44da59a99f6b324b\n  Stored in directory: /root/.cache/pip/wheels/1e/7a/db/27645fac296d5d5ba5c461b1af834eebc0ba4643290dbc5476\nSuccessfully built pypi-kenlm\nInstalling collected packages: pypi-kenlm\nSuccessfully installed pypi-kenlm-0.1.20220713\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom glob import glob\nfrom transformers import AutoFeatureExtractor, pipeline\nimport pandas as pd\nimport librosa\nimport IPython\nfrom datasets import load_metric\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport gc\nimport wave\nfrom scipy.io import wavfile\nimport scipy.signal as sps\nimport pyctcdecode\n\ntqdm.pandas()\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:50:13.821005Z","iopub.execute_input":"2023-07-28T11:50:13.821418Z","iopub.status.idle":"2023-07-28T11:50:31.416743Z","shell.execute_reply.started":"2023-07-28T11:50:13.821385Z","shell.execute_reply":"2023-07-28T11:50:31.415654Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# CHANGE ACCORDINGLY\nBATCH_SIZE = 16\nTEST_DIRECTORY = '/kaggle/input/bengaliai-speech/test_mp3s'\npaths = glob(os.path.join(TEST_DIRECTORY,'*.mp3'))\nprint(paths[:2])","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:50:45.678413Z","iopub.execute_input":"2023-07-28T11:50:45.679307Z","iopub.status.idle":"2023-07-28T11:50:45.690149Z","shell.execute_reply.started":"2023-07-28T11:50:45.679259Z","shell.execute_reply":"2023-07-28T11:50:45.688844Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['/kaggle/input/bengaliai-speech/test_mp3s/a9395e01ad21.mp3', '/kaggle/input/bengaliai-speech/test_mp3s/0f3dac00655e.mp3']\n","output_type":"stream"}]},{"cell_type":"code","source":"class CFG:\n    my_model_name = '../input/yellowking-dlsprint-model/YellowKing_model'\n    processor_name = '../input/yellowking-dlsprint-model/YellowKing_processor'","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:51:09.761264Z","iopub.execute_input":"2023-07-28T11:51:09.761674Z","iopub.status.idle":"2023-07-28T11:51:09.767524Z","shell.execute_reply.started":"2023-07-28T11:51:09.761644Z","shell.execute_reply":"2023-07-28T11:51:09.766270Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2ProcessorWithLM\n\nprocessor = Wav2Vec2ProcessorWithLM.from_pretrained(CFG.processor_name)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:51:20.584497Z","iopub.execute_input":"2023-07-28T11:51:20.584916Z","iopub.status.idle":"2023-07-28T11:52:59.530822Z","shell.execute_reply.started":"2023-07-28T11:51:20.584882Z","shell.execute_reply":"2023-07-28T11:52:59.529827Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"my_asrLM = pipeline(\"automatic-speech-recognition\", model=CFG.my_model_name ,feature_extractor =processor.feature_extractor, tokenizer= processor.tokenizer,decoder=processor.decoder ,device=0)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:53:11.843344Z","iopub.execute_input":"2023-07-28T11:53:11.843837Z","iopub.status.idle":"2023-07-28T11:53:31.184460Z","shell.execute_reply.started":"2023-07-28T11:53:11.843766Z","shell.execute_reply":"2023-07-28T11:53:31.183337Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"speech, sr = librosa.load('/kaggle/input/bengaliai-speech/test_mp3s/0f3dac00655e.mp3', sr=processor.feature_extractor.sampling_rate)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:54:01.580659Z","iopub.execute_input":"2023-07-28T11:54:01.581878Z","iopub.status.idle":"2023-07-28T11:54:11.811861Z","shell.execute_reply.started":"2023-07-28T11:54:01.581829Z","shell.execute_reply":"2023-07-28T11:54:11.810806Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"my_asrLM([speech]*2, chunk_length_s=112, stride_length_s=None)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:54:16.975333Z","iopub.execute_input":"2023-07-28T11:54:16.976265Z","iopub.status.idle":"2023-07-28T11:54:21.818047Z","shell.execute_reply.started":"2023-07-28T11:54:16.976225Z","shell.execute_reply":"2023-07-28T11:54:21.816826Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'text': 'একটু বয়স হলে একটি বিদেশি।'}, {'text': 'একটু বয়স হলে একটি বিদেশি।'}]"},"metadata":{}}]},{"cell_type":"code","source":"my_asrLM","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:54:53.969760Z","iopub.execute_input":"2023-07-28T11:54:53.970953Z","iopub.status.idle":"2023-07-28T11:54:53.978565Z","shell.execute_reply.started":"2023-07-28T11:54:53.970914Z","shell.execute_reply":"2023-07-28T11:54:53.977361Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline at 0x7aadc7301510>"},"metadata":{}}]},{"cell_type":"code","source":"class AudioDataset(Dataset):\n    def __init__(self, paths):\n        self.paths = paths\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self,idx):\n        speech, sr = librosa.load(self.paths[idx], sr=processor.feature_extractor.sampling_rate) \n#         print(speech.shape)\n        return speech","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:55:03.000452Z","iopub.execute_input":"2023-07-28T11:55:03.000891Z","iopub.status.idle":"2023-07-28T11:55:03.007881Z","shell.execute_reply.started":"2023-07-28T11:55:03.000856Z","shell.execute_reply":"2023-07-28T11:55:03.006722Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"dataset = AudioDataset(paths)\ndataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:55:12.294827Z","iopub.execute_input":"2023-07-28T11:55:12.295229Z","iopub.status.idle":"2023-07-28T11:55:12.322320Z","shell.execute_reply.started":"2023-07-28T11:55:12.295197Z","shell.execute_reply":"2023-07-28T11:55:12.320877Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([-1.7763568e-14,  4.2632564e-14,  2.2737368e-13, ...,\n       -6.2642025e-06,  2.5706822e-07, -5.0473864e-06], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"device = 'cuda:0'","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:55:21.599113Z","iopub.execute_input":"2023-07-28T11:55:21.599587Z","iopub.status.idle":"2023-07-28T11:55:21.604257Z","shell.execute_reply.started":"2023-07-28T11:55:21.599546Z","shell.execute_reply":"2023-07-28T11:55:21.603199Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def collate_fn_padd(batch):\n    '''\n    Padds batch of variable length\n\n    note: it converts things ToTensor manually here since the ToTensor transform\n    assume it takes in images rather than arbitrary tensors.\n    '''\n    ## get sequence lengths\n    lengths = torch.tensor([ t.shape[0] for t in batch ])\n    ## padd\n    batch = [ torch.Tensor(t) for t in batch ]\n    batch = torch.nn.utils.rnn.pad_sequence(batch)\n    ## compute mask\n    mask = (batch != 0)\n    return batch, lengths, mask","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:55:28.849827Z","iopub.execute_input":"2023-07-28T11:55:28.850268Z","iopub.status.idle":"2023-07-28T11:55:28.857806Z","shell.execute_reply.started":"2023-07-28T11:55:28.850234Z","shell.execute_reply":"2023-07-28T11:55:28.856682Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=8, collate_fn=collate_fn_padd)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:55:34.740647Z","iopub.execute_input":"2023-07-28T11:55:34.741173Z","iopub.status.idle":"2023-07-28T11:55:34.751195Z","shell.execute_reply.started":"2023-07-28T11:55:34.741131Z","shell.execute_reply":"2023-07-28T11:55:34.749918Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"preds_all = []\nfor batch, lengths, mask in dataloader:\n    preds = my_asrLM(list(batch.numpy().transpose()))\n    preds_all+=preds","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:55:41.805141Z","iopub.execute_input":"2023-07-28T11:55:41.805556Z","iopub.status.idle":"2023-07-28T11:55:43.328034Z","shell.execute_reply.started":"2023-07-28T11:55:41.805524Z","shell.execute_reply":"2023-07-28T11:55:43.326542Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from bnunicodenormalizer import Normalizer \n\n\nbnorm = Normalizer()\ndef normalize(sen):\n    _words = [bnorm(word)['normalized']  for word in sen.split()]\n    return \" \".join([word for word in _words if word is not None])\n\ndef dari(sentence):\n    try:\n        if sentence[-1]!=\"।\":\n            sentence+=\"।\"\n    except:\n        print(sentence)\n    return sentence","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:55:48.765714Z","iopub.execute_input":"2023-07-28T11:55:48.766195Z","iopub.status.idle":"2023-07-28T11:55:48.783036Z","shell.execute_reply.started":"2023-07-28T11:55:48.766157Z","shell.execute_reply":"2023-07-28T11:55:48.781832Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df= pd.DataFrame(\n    {\n        \"id\":[p.split(os.sep)[-1].replace('.mp3','') for p in paths],\n        \"sentence\":[p['text']for p in preds_all]\n    }\n)\ndf.sentence= df.sentence.apply(lambda x:normalize(x))\ndf.sentence= df.sentence.apply(lambda x:dari(x))","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:55:54.908379Z","iopub.execute_input":"2023-07-28T11:55:54.908855Z","iopub.status.idle":"2023-07-28T11:55:54.954184Z","shell.execute_reply.started":"2023-07-28T11:55:54.908814Z","shell.execute_reply":"2023-07-28T11:55:54.951946Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-07-28T11:55:59.304651Z","iopub.execute_input":"2023-07-28T11:55:59.305420Z","iopub.status.idle":"2023-07-28T11:55:59.327072Z","shell.execute_reply.started":"2023-07-28T11:55:59.305385Z","shell.execute_reply":"2023-07-28T11:55:59.325964Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"             id                                           sentence\n0  a9395e01ad21  কী কারণে তুমি এতাবৎ কাল পর্যন্ত এ দারুন দৈব দু...\n1  0f3dac00655e                          একটু বয়স হলে একটি বিদেশি।\n2  bf36ea8b718d  এ কারণে সরকার নির্ধারিত হারে পরিবহন জনিত ক্ষতি...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a9395e01ad21</td>\n      <td>কী কারণে তুমি এতাবৎ কাল পর্যন্ত এ দারুন দৈব দু...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0f3dac00655e</td>\n      <td>একটু বয়স হলে একটি বিদেশি।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bf36ea8b718d</td>\n      <td>এ কারণে সরকার নির্ধারিত হারে পরিবহন জনিত ক্ষতি...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}